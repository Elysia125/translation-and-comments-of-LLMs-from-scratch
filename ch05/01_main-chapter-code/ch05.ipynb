{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45398736-7e89-4263-89c8-92153baff553",
   "metadata": {},
   "source": [
    "<table style=\"width:100%\">\n",
    "<tr>\n",
    "<td style=\"vertical-align:middle; text-align:left;\">\n",
    "<font size=\"2\">\n",
    "Supplementary code for the <a href=\"http://mng.bz/orYv\">Build a Large Language Model From Scratch</a> book by <a href=\"https://sebastianraschka.com\">Sebastian Raschka</a><br>\n",
    "<br>Code repository: <a href=\"https://github.com/rasbt/LLMs-from-scratch\">https://github.com/rasbt/LLMs-from-scratch</a>\n",
    "</font>\n",
    "</td>\n",
    "<td style=\"vertical-align:middle; text-align:left;\">\n",
    "<a href=\"http://mng.bz/orYv\"><img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/cover-small.webp\" width=\"100px\"></a>\n",
    "</td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66dd524e-864c-4012-b0a2-ccfc56e80024",
   "metadata": {
    "id": "66dd524e-864c-4012-b0a2-ccfc56e80024"
   },
   "source": [
    "# Chapter 5: Pretraining on Unlabeled Data\n",
    "# 第五章：在未标记数据上预训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92b989e9-da36-4159-b212-799184764dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib version: 3.9.2\n",
      "numpy version: 1.26.4\n",
      "tiktoken version: 0.8.0\n",
      "torch version: 2.5.0\n",
      "tensorflow version: 2.18.0\n"
     ]
    }
   ],
   "source": [
    "# 导入版本检查模块\n",
    "from importlib.metadata import version\n",
    "\n",
    "# 定义需要检查版本的包列表\n",
    "pkgs = [\"matplotlib\", \n",
    "        \"numpy\", \n",
    "        \"tiktoken\", \n",
    "        \"torch\",\n",
    "        \"tensorflow\" # 用于加载OpenAI的预训练权重\n",
    "       ]\n",
    "\n",
    "# 遍历包列表并打印每个包的版本号\n",
    "for p in pkgs:\n",
    "    print(f\"{p} version: {version(p)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3bdf9e-2ff0-4a57-abab-ede2d955a237",
   "metadata": {},
   "source": [
    "- In this chapter, we implement the training loop and code for basic model evaluation to pretrain an LLM\n",
    "- At the end of this chapter, we also load openly available pretrained weights from OpenAI into our model\n",
    "- 在本章中,我们将实现训练循环和基本模型评估代码来预训练一个大语言模型\n",
    "- 在本章最后,我们还会将OpenAI的开源预训练权重加载到我们的模型中"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd27fcc-2886-47cb-b544-046c2c31f02a",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/chapter-overview.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d214765-7a73-42d5-95e9-302154b29db9",
   "metadata": {},
   "source": [
    "- The topics covered in this chapter are shown below\n",
    "- 本章涵盖的主题如下所示"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67711d4-8391-4fee-aeef-07ea53dd5841",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/mental-model--0.webp\" width=400px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d824183-145c-4865-89e1-1f0d0a338f19",
   "metadata": {
    "id": "0d824183-145c-4865-89e1-1f0d0a338f19"
   },
   "source": [
    "## 5.1 Evaluating generative text models\n",
    "## 5.1 评估生成式文本模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3350f8c-5181-4f9b-a789-4523105e98f2",
   "metadata": {},
   "source": [
    "- We start this section with a brief recap of initializing a GPT model using the code from the previous chapter\n",
    "- 我们从简要回顾使用上一章的代码初始化GPT模型开始本节\n",
    " - Then, we discuss basic evaluation metrics for LLMs \n",
    "- 然后,我们讨论大语言模型的基本评估指标\n",
    " - Lastly, in this section, we apply these evaluation metrics to a training and validation dataset\n",
    "- 最后,在本节中,我们将这些评估指标应用于训练集和验证集"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc1cf3f-82d8-46c7-9ecc-58979ce87cdd",
   "metadata": {
    "id": "bdc1cf3f-82d8-46c7-9ecc-58979ce87cdd"
   },
   "source": [
    "### 5.1.1 Using GPT to generate text\n",
    "### 5.1.1 使用GPT生成文本"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3415fd-9f4a-4548-908e-9dfa56edc9bc",
   "metadata": {},
   "source": [
    "- We initialize a GPT model using the code from the previous chapter\n",
    "- 我们使用上一章的代码初始化GPT模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86000d74-624a-48f0-86da-f41926cb9e04",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "86000d74-624a-48f0-86da-f41926cb9e04",
    "outputId": "ad482cfd-5a62-4f0d-e1e0-008d6457f512"
   },
   "outputs": [],
   "source": [
    "# 导入PyTorch库\n",
    "import torch\n",
    "# 从前面章节导入GPT模型\n",
    "from previous_chapters import GPTModel\n",
    "\n",
    "# 定义GPT-124M模型的配置参数\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,   # 词汇表大小\n",
    "    \"context_length\": 256, # 缩短的上下文长度(原始为1024)\n",
    "    \"emb_dim\": 768,        # 嵌入维度\n",
    "    \"n_heads\": 12,         # 注意力头数量\n",
    "    \"n_layers\": 12,        # 层数\n",
    "    \"drop_rate\": 0.1,      # Dropout比率\n",
    "    \"qkv_bias\": False      # 是否使用Query-Key-Value偏置\n",
    "}\n",
    "\n",
    "# 设置随机种子以确保可重复性\n",
    "torch.manual_seed(123)\n",
    "# 初始化GPT模型\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "# 将模型设置为评估模式,禁用dropout\n",
    "model.eval();  # 在推理过程中禁用dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c6cf0f-7458-48a2-97fd-aa5068d65e8c",
   "metadata": {},
   "source": [
    "- We use dropout of 0.1 above, but it's relatively common to train LLMs without dropout nowadays\n",
    "- 我们在上面使用了0.1的dropout,但现在训练大语言模型通常不使用dropout\n",
    "- Modern LLMs also don't use bias vectors in the `nn.Linear` layers for the query, key, and value matrices (unlike earlier GPT models), which is achieved by setting `\"qkv_bias\": False`\n",
    "- 现代大语言模型在query、key和value矩阵的`nn.Linear`层中也不使用偏置向量(与早期GPT模型不同),这是通过设置`\"qkv_bias\": False`实现的\n",
    "- We reduce the context length (`context_length`) of only 256 tokens to reduce the computational resource requirements for training the model, whereas the original 124 million parameter GPT-2 model used 1024 tokens\n",
    "- 我们将上下文长度(`context_length`)减少到仅256个token以降低模型训练的计算资源需求,而原始的1.24亿参数的GPT-2模型使用了1024个token\n",
    "  - This is so that more readers will be able to follow and execute the code examples on their laptop computer\n",
    "  - 这样更多读者可以在他们的笔记本电脑上运行和执行代码示例\n",
    "  - However, please feel free to increase the `context_length` to 1024 tokens (this would not require any code changes)\n",
    "  - 但是,您可以随意将`context_length`增加到1024个token(这不需要任何代码更改)\n",
    "  - We will also load a model with a 1024 `context_length` later from pretrained weights\n",
    "  - 稍后我们还将从预训练权重加载一个具有1024 `context_length`的模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f80895-be35-4bb5-81cb-f357ef7367fe",
   "metadata": {},
   "source": [
    "- Next, we use the `generate_text_simple` function from the previous chapter to generate text\n",
    "- 接下来,我们使用上一章的`generate_text_simple`函数来生成文本\n",
    "- In addition, we define two convenience functions, `text_to_token_ids` and `token_ids_to_text`, for converting between token and text representations that we use throughout this chapter\n",
    "- 此外,我们定义了两个便利函数`text_to_token_ids`和`token_ids_to_text`,用于在本章中进行token和文本表示之间的转换"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741881f3-cee0-49ad-b11d-b9df3b3ac234",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/gpt-process.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e062b82-3540-48ce-8eb4-009686d0d16c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you rentingetic wasnم refres RexMeCHicular stren\n"
     ]
    }
   ],
   "source": [
    "# 导入tiktoken分词器库\n",
    "import tiktoken\n",
    "# 从之前的章节导入文本生成函数\n",
    "from previous_chapters import generate_text_simple\n",
    "\n",
    "# 将文本转换为token ID的函数\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    # 使用tokenizer将文本编码为token ID,允许特殊token '<|endoftext|>'\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    # 将编码后的token ID转换为tensor并添加batch维度\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add batch dimension\n",
    "    return encoded_tensor\n",
    "\n",
    "# 将token ID转换回文本的函数\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    # 移除batch维度\n",
    "    flat = token_ids.squeeze(0) # remove batch dimension\n",
    "    # 使用tokenizer将token ID解码为文本\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "# 设置初始上下文文本\n",
    "start_context = \"Every effort moves you\"\n",
    "# 初始化GPT-2分词器\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "# 使用模型生成文本\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,  # 使用已定义的模型\n",
    "    idx=text_to_token_ids(start_context, tokenizer),  # 将初始文本转换为token ID\n",
    "    max_new_tokens=10,  # 最多生成10个新token\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]  # 使用模型配置中定义的上下文长度\n",
    ")\n",
    "\n",
    "# 打印生成的文本结果\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d3249b-b2a0-44c4-b589-ae4b403b8305",
   "metadata": {},
   "source": [
    " - As we can see above, the model does not produce good text because it has not been trained yet\n",
    "- 如上所示,模型还没有经过训练,所以无法生成好的文本\n",
    " - How do we measure or capture what \"good text\" is, in a numeric form, to track it during training?\n",
    "- 在训练过程中,我们如何以数字形式衡量或捕捉什么是\"好的文本\"?\n",
    " - The next subsection introduces metrics to calculate a loss metric for the generated outputs that we can use to measure the training progress\n",
    "- 下一小节将介绍用于计算生成输出的损失指标的方法,我们可以用它来衡量训练进度\n",
    " - The next chapters on finetuning LLMs will also introduce additional ways to measure model quality\n",
    "- 后续关于微调LLM的章节还将介绍其他衡量模型质量的方法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955f9e1a-7bf7-40d8-b1fa-eacabdee8d8e",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3d7ea2-637f-4490-bc76-e361fc81ae98",
   "metadata": {
    "id": "0f3d7ea2-637f-4490-bc76-e361fc81ae98"
   },
   "source": [
    "### 5.1.2 Calculating the text generation loss: cross-entropy and perplexity\n",
    "### 5.1.2 计算文本生成损失:交叉熵和困惑度"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1ba8aa-fb03-4d25-957f-fe8778762440",
   "metadata": {},
   "source": [
    " - Suppose we have an `inputs` tensor containing the token IDs for 2 training examples (rows)\n",
    "- 假设我们有一个包含2个训练样例(行)的token ID的`inputs`张量\n",
    " - Corresponding to the `inputs`, the `targets` contain the desired token IDs that we want the model to generate  \n",
    "- 对应于`inputs`，`targets`包含了我们希望模型生成的目标token ID\n",
    " - Notice that the `targets` are the `inputs` shifted by 1 position, as explained in chapter 2 when we implemented the data loader\n",
    "- 注意`targets`是`inputs`向后移动1个位置得到的,这在第2章实现数据加载器时已经解释过"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b5402f8-ec0c-4a44-9892-18a97779ee4f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6b5402f8-ec0c-4a44-9892-18a97779ee4f",
    "outputId": "8d6fa0ff-7b37-4634-c3f0-2c050cbe81f0"
   },
   "outputs": [],
   "source": [
    "# 输入张量,包含两个训练样例的token ID序列\n",
    "# 第一行: \"every effort moves\"\n",
    "# 第二行: \"I really like\" \n",
    "inputs = torch.tensor([[16833, 3626, 6100],   # [\"every effort moves\",\n",
    "                       [40,    1107, 588]])   #  \"I really like\"]\n",
    "\n",
    "# 目标张量,是输入向右移动一位得到的序列\n",
    "# 第一行: \" effort moves you\" \n",
    "# 第二行: \" really like chocolate\"\n",
    "targets = torch.tensor([[3626, 6100, 345  ],  # [\" effort moves you\",\n",
    "                        [1107,  588, 11311]]) #  \" really like chocolate\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33dc0645-ac2c-4973-9b40-6da40515bede",
   "metadata": {},
   "source": [
    "- Feeding the `inputs` to the model, we obtain the logits vector for the 2 input examples that consist of 3 tokens each\n",
    "- 将`inputs`输入模型,我们得到2个输入样例的logits向量,每个样例包含3个token\n",
    "- Each of the tokens is a 50,257-dimensional vector corresponding to the size of the vocabulary  \n",
    "- 每个token都是一个50,257维的向量,对应词汇表的大小\n",
    "- Applying the softmax function, we can turn the logits tensor into a tensor of the same dimension containing probability scores\n",
    "- 应用softmax函数,我们可以将logits张量转换为相同维度的概率分数张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7b6ec51-6f8c-49bd-a349-95ba38b46fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50257])\n"
     ]
    }
   ],
   "source": [
    "# 使用torch.no_grad()避免计算梯度\n",
    "with torch.no_grad():\n",
    "    # 将输入传入模型得到logits\n",
    "    logits = model(inputs)\n",
    "\n",
    "# 对logits应用softmax得到每个词汇表中token的概率分布\n",
    "probas = torch.softmax(logits, dim=-1) # 词汇表中每个token的概率\n",
    "print(probas.shape) # 形状: (批次大小, token数量, 词汇表大小)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c36a382-b5e2-4de6-9e65-0b69b685013b",
   "metadata": {},
   "source": [
    " - The figure below, using a very small vocabulary for illustration purposes, outlines how we convert the probability scores back into text, which we discussed at the end of the previous chapter\n",
    " - 下图使用了一个非常小的词汇表作为示例，概述了如何将概率分数转换回文本，这是我们在上一章末尾讨论过的内容"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384d86a9-0013-476c-bb6b-274fd5f20b29",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/proba-to-text.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8480efd-d419-4954-9ecc-2876055334bd",
   "metadata": {},
   "source": [
    "- As discussed in the previous chapter, we can apply the `argmax` function to convert the probability scores into predicted token IDs\n",
    "- 如前一章所述,我们可以使用`argmax`函数将概率分数转换为预测的token ID\n",
    "- The softmax function above produced a 50,257-dimensional vector for each token; the `argmax` function returns the position of the highest probability score in this vector, which is the predicted token ID for the given token\n",
    "- 上面的softmax函数为每个token生成了一个50,257维的向量;`argmax`函数返回这个向量中最高概率分数的位置,即给定token的预测token ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b84c9f-dd08-482e-b903-a86fe44e1144",
   "metadata": {},
   "source": [
    " - Since we have 2 input batches with 3 tokens each, we obtain 2 by 3 predicted token IDs:\n",
    "- 由于我们有2个输入批次,每个批次包含3个token,我们得到2×3的预测token ID:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34ebd76a-16ec-4c17-8958-8a135735cc1c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "34ebd76a-16ec-4c17-8958-8a135735cc1c",
    "outputId": "ed17da47-c3e7-4775-fd00-4ec5bcda3db2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      " tensor([[[16657],\n",
      "         [  339],\n",
      "         [42826]],\n",
      "\n",
      "        [[49906],\n",
      "         [29669],\n",
      "         [41751]]])\n"
     ]
    }
   ],
   "source": [
    "# 使用argmax函数找出每个位置概率最高的token ID\n",
    "# dim=-1表示在最后一个维度(词汇表维度)上取最大值\n",
    "# keepdim=True保持输出维度与输入一致\n",
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "print(\"Token IDs:\\n\", token_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee4072c-21ed-4df7-8721-dd2535362573",
   "metadata": {},
   "source": [
    " - If we decode these tokens, we find that these are quite different from the tokens we want the model to predict, namely the target tokens:\n",
    " - 如果我们对这些token进行解码，会发现它们与我们希望模型预测的目标token有很大的不同："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c990ead6-53cd-49a7-a6d1-14d8c1518249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets batch 1:  effort moves you\n",
      "Outputs batch 1:  Armed heNetflix\n"
     ]
    }
   ],
   "source": [
    "# 打印第一个批次的目标token序列\n",
    "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "# 打印第一个批次的模型输出token序列\n",
    "print(f\"Outputs batch 1: {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53eb8a7-070e-46d6-930c-314ba55a6ff2",
   "metadata": {},
   "source": [
    " - That's because the model wasn't trained yet\n",
    " - 这是因为模型还没有经过训练\n",
    " - To train the model, we need to know how far it is away from the correct predictions (targets)\n",
    " - 要训练模型，我们需要知道它与正确预测（目标）的差距有多大"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad90592f-0d5d-4ec8-9ff5-e7675beab10e",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/proba-index.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7251bf5-a079-4782-901d-68c9225d3157",
   "metadata": {},
   "source": [
    " - The token probabilities corresponding to the target indices are as follows:\n",
    " - 目标索引对应的token概率如下:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54aef09c-d6e3-4238-8653-b3a1b0a1077a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "54aef09c-d6e3-4238-8653-b3a1b0a1077a",
    "outputId": "41c946a2-c458-433e-a53d-5e7e89d9dddc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1: tensor([7.4541e-05, 3.1061e-05, 1.1563e-05])\n",
      "Text 2: tensor([1.0337e-05, 5.6776e-05, 4.7559e-06])\n"
     ]
    }
   ],
   "source": [
    "# 处理第一个文本序列\n",
    "text_idx = 0  # 选择第一个批次\n",
    "# 从probas张量中提取第一个文本序列对应的目标token概率\n",
    "# probas[text_idx]选择第一个批次\n",
    "# [0,1,2]选择序列中的3个位置\n",
    "# targets[text_idx]选择对应的目标token ID\n",
    "target_probas_1 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 1:\", target_probas_1)\n",
    "\n",
    "# 处理第二个文本序列\n",
    "text_idx = 1  # 选择第二个批次\n",
    "# 从probas张量中提取第二个文本序列对应的目标token概率\n",
    "# 索引方式与上面相同,但是使用第二个批次的数据\n",
    "target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 2:\", target_probas_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e89a19-73c2-4e49-93b4-861f699f1cbf",
   "metadata": {},
   "source": [
    " - We want to maximize all these values, bringing them close to a probability of 1\n",
    " - 我们希望最大化所有这些值，使它们接近于概率1\n",
    " - In mathematical optimization, it is easier to maximize the logarithm of the probability score than the probability score itself; this is out of the scope of this book, but I have recorded a lecture with more details here: [L8.2 Logistic Regression Loss Function](https://www.youtube.com/watch?v=GxJe0DZvydM)\n",
    " - 在数学优化中，最大化概率分数的对数比最大化概率分数本身更容易；这超出了本书的范围，但我在这里录制了一个包含更多细节的讲座：[L8.2 逻辑回归损失函数](https://www.youtube.com/watch?v=GxJe0DZvydM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31402a67-a16e-4aeb-977e-70abb9c9949b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "31402a67-a16e-4aeb-977e-70abb9c9949b",
    "outputId": "1bf18e79-1246-4eab-efd8-12b328c78678"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -9.5042, -10.3796, -11.3677, -11.4798,  -9.7764, -12.2561])\n"
     ]
    }
   ],
   "source": [
    "# 计算所有token概率的对数\n",
    "# 使用torch.cat连接两个目标概率张量\n",
    "# 然后使用torch.log计算对数值\n",
    "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
    "print(log_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4261441-a511-4633-9c4c-67998af31b84",
   "metadata": {},
   "source": [
    "- Next, we compute the average log probability:\n",
    "- 接下来，我们计算平均对数概率："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b003797-161b-4d98-81dc-e68320e09fec",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9b003797-161b-4d98-81dc-e68320e09fec",
    "outputId": "a447fe9c-7e27-40ed-f1fb-51210e3f7cc9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-10.7940)\n"
     ]
    }
   ],
   "source": [
    "# Calculate the average probability for each token\n",
    "# 计算每个token的平均概率\n",
    "avg_log_probas = torch.mean(log_probas)\n",
    "print(avg_log_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d51994-ad17-4ba3-a6ec-f588b4b13585",
   "metadata": {},
   "source": [
    "- The goal is to make this average log probability as large as possible by optimizing the model weights\n",
    "- 目标是通过优化模型权重使这个平均对数概率尽可能大\n",
    "\n",
    "- Due to the log, the largest possible value is 0, and we are currently far away from 0\n",
    "- 由于对数的特性，最大可能值是0，而我们目前离0还很远"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de388a1-8a0a-4c94-8894-9041dc6ad514",
   "metadata": {},
   "source": [
    "- In deep learning, instead of maximizing the average log-probability, it's a standard convention to minimize the *negative* average log-probability value; in our case, instead of maximizing -10.7722 so that it approaches 0, in deep learning, we would minimize 10.7722 so that it approaches 0\n",
    "- 在深度学习中，与其最大化平均对数概率，标准做法是最小化*负*平均对数概率值；在我们的例子中，与其最大化 -10.7722 使其接近0，在深度学习中，我们会最小化 10.7722 使其接近0\n",
    "- The value negative of -10.7722, i.e., 10.7722, is also called cross-entropy loss in deep learning\n",
    "- -10.7722的负值，即10.7722，在深度学习中也被称为交叉熵损失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "176ddf35-1c5f-4d7c-bf17-70f3e7069bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "# 计算负平均对数概率\n",
    "# 将平均对数概率乘以-1得到交叉熵损失\n",
    "neg_avg_log_probas = avg_log_probas * -1\n",
    "print(neg_avg_log_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84eeb868-abd8-4028-82db-107546bf7c2c",
   "metadata": {},
   "source": [
    "- PyTorch already implements a `cross_entropy` function that carries out the previous steps\n",
    "- PyTorch已经实现了一个`cross_entropy`函数来执行前面的步骤"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd24b7f-b760-47ad-bc84-86d13794aa54",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/cross-entropy.webp?123\" width=400px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8aaf9dd-3ee6-42bf-a63f-6e93dbfb989d",
   "metadata": {},
   "source": [
    "- Before we apply the `cross_entropy` function, let's check the shape of the logits and targets\n",
    "- 在应用`cross_entropy`函数之前，让我们检查logits和targets的形状"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "695d6f64-5084-4c23-aea4-105c9e38cfe4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "695d6f64-5084-4c23-aea4-105c9e38cfe4",
    "outputId": "43fd802a-8136-4b35-df0d-f61a5d4cb561"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([2, 3, 50257])\n",
      "Targets shape: torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "# logits的形状是(batch_size, num_tokens, vocab_size)\n",
    "print(\"Logits shape:\", logits.shape)\n",
    "\n",
    "# targets的形状是(batch_size, num_tokens) \n",
    "print(\"Targets shape:\", targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3d65f0-6566-4865-93e4-0c0bcb10cd06",
   "metadata": {},
   "source": [
    "- For the `cross_entropy` function in PyTorch, we want to flatten these tensors by combining them over the batch dimension:\n",
    "- 对于PyTorch中的`cross_entropy`函数，我们需要通过在batch维度上合并这些张量来将它们展平："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e17e027-ab9f-4fb5-ac9b-a009b831c122",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0e17e027-ab9f-4fb5-ac9b-a009b831c122",
    "outputId": "0b2b778b-02fb-43b2-c879-adc59055a7d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened logits: torch.Size([6, 50257])\n",
      "Flattened targets: torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "# 将logits张量在第0和第1维度上展平\n",
    "logits_flat = logits.flatten(0, 1)\n",
    "# 将targets张量完全展平\n",
    "targets_flat = targets.flatten()\n",
    "\n",
    "# 打印展平后的形状\n",
    "print(\"Flattened logits:\", logits_flat.shape)\n",
    "print(\"Flattened targets:\", targets_flat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4921a57f-3a79-473e-a863-6d63b495010f",
   "metadata": {},
   "source": [
    "- Note that the targets are the token IDs, which also represent the index positions in the logits tensors that we want to maximize\n",
    "- 请注意，targets是token ID，它们也表示我们想要最大化的logits张量中的索引位置\n",
    "- The `cross_entropy` function in PyTorch will automatically take care of applying the softmax and log-probability computation internally over those token indices in the logits that are to be maximized\n",
    "- PyTorch中的`cross_entropy`函数会自动处理在logits中需要最大化的token索引上的softmax和对数概率计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62d0816e-b29a-4c8f-a9a5-a167562de978",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "62d0816e-b29a-4c8f-a9a5-a167562de978",
    "outputId": "c0be634a-2c65-4ff7-a73f-1bfc2e406ba4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "# 使用PyTorch的交叉熵损失函数计算损失值\n",
    "# logits_flat: 展平后的logits张量\n",
    "# targets_flat: 展平后的目标张量\n",
    "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "# 打印损失值\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f15ce17-fd7b-4d8e-99da-b237523a7a80",
   "metadata": {},
   "source": [
    "- A concept related to the cross-entropy loss is the perplexity of an LLM\n",
    "- 与交叉熵损失相关的一个概念是LLM的困惑度\n",
    "- The perplexity is simply the exponential of the cross-entropy loss  \n",
    "- 困惑度就是交叉熵损失的指数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "168952a1-b964-4aa7-8e49-966fa26add54",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "168952a1-b964-4aa7-8e49-966fa26add54",
    "outputId": "a0a692c1-6412-4068-8aa5-8858548141eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(48725.8203)\n"
     ]
    }
   ],
   "source": [
    "# 计算困惑度（perplexity）：交叉熵损失的指数\n",
    "perplexity = torch.exp(loss)\n",
    "# 打印困惑度值\n",
    "print(perplexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ae26dd-d77e-41fd-b924-6bd103dd4ee7",
   "metadata": {},
   "source": [
    "- The perplexity is often considered more interpretable because it can be understood as the effective vocabulary size that the model is uncertain about at each step (in the example above, that'd be 48,725 words or tokens)\n",
    "- 困惑度通常被认为更容易理解，因为它可以被理解为模型在每一步中不确定的有效词汇量大小（在上面的例子中，大约是48,725个单词或标记）\n",
    "\n",
    "- In other words, perplexity provides a measure of how well the probability distribution predicted by the model matches the actual distribution of the words in the dataset\n",
    "- 换句话说，困惑度提供了一个衡量标准，用于衡量模型预测的概率分布与数据集中单词的实际分布的匹配程度\n",
    "\n",
    "- Similar to the loss, a lower perplexity indicates that the model predictions are closer to the actual distribution\n",
    "- 与损失类似，较低的困惑度表明模型的预测更接近实际分布"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec6c217-e429-40c7-ad71-5d0a9da8e487",
   "metadata": {
    "id": "2ec6c217-e429-40c7-ad71-5d0a9da8e487"
   },
   "source": [
    "### 5.1.3 Calculating the training and validation set losses\n",
    "### 5.1.3 计算训练集和验证集的损失"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530da89e-2448-436c-8f1b-28e8a31ef85c",
   "metadata": {},
   "source": [
    "- We use a relatively small dataset for training the LLM (in fact, only one short story)\n",
    "- 我们使用相对较小的数据集来训练LLM（实际上只有一个短故事）\n",
    "- The reasons are:\n",
    "- 原因如下：\n",
    "  - You can run the code examples in a few minutes on a laptop computer without a suitable GPU\n",
    "  - 你可以在没有合适GPU的笔记本电脑上在几分钟内运行代码示例\n",
    "  - The training finishes relatively fast (minutes instead of weeks), which is good for educational purposes\n",
    "  - 训练完成相对较快（几分钟而不是几周），这对教育目的来说很好\n",
    "  - We use a text from the public domain, which can be included in this GitHub repository without violating any usage rights or bloating the repository size\n",
    " - 我们使用来自公共领域的文本，可以将其包含在这个GitHub仓库中而不违反任何使用权或增加仓库大小\n",
    "\n",
    "\n",
    "- For example, Llama 2 7B required 184,320 GPU hours on A100 GPUs to be trained on 2 trillion tokens\n",
    "- 例如，Llama 2 7B需要在A100 GPU上使用184,320 GPU小时来训练2万亿个tokens\n",
    "  - At the time of this writing, the hourly cost of an 8xA100 cloud server at AWS is approximately \\\\$30\n",
    "  - 在撰写本文时，AWS上8xA100云服务器的每小时成本约为30美元\n",
    "  - So, via an off-the-envelope calculation, training this LLM would cost 184,320 / 8 * \\\\$30 =  \\\\$690,000\n",
    "  - 因此，通过粗略计算，训练这个LLM的成本将是184,320 / 8 * 30美元 = 690,000美元\n",
    "\n",
    "- Below, we use the same dataset we used in chapter 2\n",
    "- 下面，我们使用与第2章相同的数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "654fde37-b2a9-4a20-a8d3-0206c056e2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入所需的库\n",
    "import os\n",
    "import urllib.request\n",
    "\n",
    "# 设置文件路径和URL\n",
    "file_path = \"the-verdict.txt\"\n",
    "url = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/the-verdict.txt\"\n",
    "\n",
    "# 如果文件不存在,则从URL下载\n",
    "if not os.path.exists(file_path):\n",
    "    # 打开URL并读取内容\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        text_data = response.read().decode('utf-8')\n",
    "    # 将内容写入本地文件\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(text_data)\n",
    "# 如果文件已存在,则直接读取\n",
    "else:\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        text_data = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379330f1-80f4-4e34-8724-41d892b04cee",
   "metadata": {},
   "source": [
    "- A quick check that the text loaded ok by printing the first and last 100 words\n",
    "- 通过打印前100个和后100个单词快速检查文本是否正确加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6kgJbe4ehI4q",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "6kgJbe4ehI4q",
    "outputId": "9ff31e88-ee37-47e9-ee64-da6eb552f46f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n"
     ]
    }
   ],
   "source": [
    "# 打印前100个字符\n",
    "print(text_data[:99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "j2XPde_ThM_e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "j2XPde_ThM_e",
    "outputId": "a900c1b9-9a87-4078-968b-a5721deda5cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it for me! The Strouds stand alone, and happen once--but there's no exterminating our kind of art.\"\n"
     ]
    }
   ],
   "source": [
    "# 打印最后100个字符\n",
    "print(text_data[-99:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6b46a952-d50a-4837-af09-4095698f7fd1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6b46a952-d50a-4837-af09-4095698f7fd1",
    "outputId": "c2a25334-21ca-486e-8226-0296e5fc6486"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: 20479\n",
      "Tokens: 5145\n"
     ]
    }
   ],
   "source": [
    "# 计算文本的总字符数\n",
    "total_characters = len(text_data)\n",
    "# 计算文本的总token数\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "\n",
    "# 打印统计结果\n",
    "print(\"Characters:\", total_characters)\n",
    "print(\"Tokens:\", total_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8830cb9-90f6-4e7c-8620-beeabc2d39f7",
   "metadata": {},
   "source": [
    "- With 5,145 tokens, the text is very short for training an LLM, but again, it's for educational purposes (we will also load pretrained weights later)\n",
    "- 有5,145个tokens的文本对于训练LLM来说非常短,但这只是出于教育目的(我们稍后也会加载预训练权重)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedcad87-a0e8-4b9d-ac43-4e927ccbb50f",
   "metadata": {},
   "source": [
    "- Next, we divide the dataset into a training and a validation set and use the data loaders from chapter 2 to prepare the batches for LLM training\n",
    "- 接下来，我们将数据集分为训练集和验证集，并使用第2章的数据加载器为LLM训练准备批次数据\n",
    "- For visualization purposes, the figure below assumes a `max_length=6`, but for the training loader, we set the `max_length` equal to the context length that the LLM supports\n",
    "- 为了便于可视化，下图假设`max_length=6`，但对于训练加载器，我们将`max_length`设置为等于LLM支持的上下文长度\n",
    "- The figure below only shows the input tokens for simplicity\n",
    "- 为了简单起见，下图仅显示输入tokens\n",
    "    - Since we train the LLM to predict the next word in the text, the targets look the same as these inputs, except that the targets are shifted by one position\n",
    "    - 由于我们训练LLM来预测文本中的下一个单词，目标看起来与这些输入相同，只是目标位置向后移动了一个位置"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bdaa07-ba96-4ac1-9d71-b3cc153910d9",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/batching.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0959c855-f860-4358-8b98-bc654f047578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从前面章节导入数据加载器函数\n",
    "from previous_chapters import create_dataloader_v1\n",
    "\n",
    "# 设置训练集和验证集的比例为90:10\n",
    "train_ratio = 0.90\n",
    "# 计算分割点索引\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "# 分割训练数据\n",
    "train_data = text_data[:split_idx]\n",
    "# 分割验证数据\n",
    "val_data = text_data[split_idx:]\n",
    "\n",
    "# 设置随机种子以确保可重复性\n",
    "torch.manual_seed(123)\n",
    "\n",
    "# 创建训练数据加载器\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,                                      # 训练数据\n",
    "    batch_size=2,                                    # 批次大小为2\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],    # 最大序列长度\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],        # 步长等于上下文长度\n",
    "    drop_last=True,                                  # 丢弃最后不完整的批次\n",
    "    shuffle=True,                                    # 随机打乱数据\n",
    "    num_workers=0                                    # 不使用多进程加载\n",
    ")\n",
    "\n",
    "# 创建验证数据加载器\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,                                        # 验证数据\n",
    "    batch_size=2,                                    # 批次大小为2\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],    # 最大序列长度\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],        # 步长等于上下文长度\n",
    "    drop_last=False,                                 # 保留最后不完整的批次\n",
    "    shuffle=False,                                   # 不打乱数据\n",
    "    num_workers=0                                    # 不使用多进程加载\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f37b3eb0-854e-4895-9898-fa7d1e67566e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "# 检查训练集的token数量是否足够\n",
    "if total_tokens * (train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\"Not enough tokens for the training loader. \"\n",
    "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
    "          \"increase the `training_ratio`\")\n",
    "\n",
    "# 检查验证集的token数量是否足够  \n",
    "if total_tokens * (1-train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\"Not enough tokens for the validation loader. \"\n",
    "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
    "          \"decrease the `training_ratio`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ac3296-a4d1-4303-9ac5-376518960c33",
   "metadata": {},
   "source": [
    "- We use a relatively small batch size to reduce the computational resource demand, and because the dataset is very small to begin with\n",
    "- 我们使用相对较小的批量大小来减少计算资源需求，同时也因为数据集本身很小\n",
    "- Llama 2 7B was trained with a batch size of 1024, for example\n",
    "- 例如，Llama 2 7B模型训练时使用的批量大小是1024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e0514d-b990-4dc0-9afb-7721993284a0",
   "metadata": {},
   "source": [
    "- An optional check that the data was loaded correctly:\n",
    "- 一个可选的检查,用于验证数据是否正确加载:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ca0116d0-d229-472c-9fbf-ebc229331c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "# 打印训练数据加载器中的批次形状\n",
    "print(\"Train loader:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)  # 打印输入x和目标y的形状\n",
    "\n",
    "# 打印验证数据加载器中的批次形状 \n",
    "print(\"\\nValidation loader:\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)  # 打印输入x和目标y的形状"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b9b1a4-863d-456f-a8dd-c07fb5c024ed",
   "metadata": {},
   "source": [
    "- Another optional check that the token sizes are in the expected ballpark:\n",
    "- 另一个可选的检查，用于验证token数量是否在预期范围内："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eb860488-5453-41d7-9870-23b723f742a0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eb860488-5453-41d7-9870-23b723f742a0",
    "outputId": "96b9451a-9557-4126-d1c8-51610a1995ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training tokens: 4608\n",
      "Validation tokens: 512\n",
      "All tokens: 5120\n"
     ]
    }
   ],
   "source": [
    "# 初始化训练集token计数器\n",
    "train_tokens = 0\n",
    "# 遍历训练数据加载器中的每个批次\n",
    "for input_batch, target_batch in train_loader:\n",
    "    # 累加当前批次中的token数量\n",
    "    train_tokens += input_batch.numel()\n",
    "\n",
    "# 初始化验证集token计数器 \n",
    "val_tokens = 0\n",
    "# 遍历验证数据加载器中的每个批次\n",
    "for input_batch, target_batch in val_loader:\n",
    "    # 累加当前批次中的token数量\n",
    "    val_tokens += input_batch.numel()\n",
    "\n",
    "# 打印训练集的token总数\n",
    "print(\"Training tokens:\", train_tokens)\n",
    "# 打印验证集的token总数\n",
    "print(\"Validation tokens:\", val_tokens)\n",
    "# 打印所有数据的token总数\n",
    "print(\"All tokens:\", train_tokens + val_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3085e8-665e-48eb-bb41-cdde61537e06",
   "metadata": {},
   "source": [
    "- Next, we implement a utility function to calculate the cross-entropy loss of a given batch\n",
    "- 接下来,我们实现一个工具函数来计算给定批次的交叉熵损失\n",
    "- In addition, we implement a second utility function to compute the loss for a user-specified number of batches in a data loader\n",
    "- 此外,我们实现第二个工具函数来计算数据加载器中用户指定批次数量的损失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7b9de31e-4096-47b3-976d-b6d2fdce04bc",
   "metadata": {
    "id": "7b9de31e-4096-47b3-976d-b6d2fdce04bc"
   },
   "outputs": [],
   "source": [
    "# 计算单个批次的损失函数\n",
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    # 将输入和目标数据移动到指定设备(CPU/GPU)\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    # 通过模型前向传播得到logits输出\n",
    "    logits = model(input_batch)\n",
    "    # 计算交叉熵损失\n",
    "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
    "    # 返回损失值\n",
    "    return loss\n",
    "\n",
    "\n",
    "# 计算数据加载器中多个批次的平均损失\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    # 初始化总损失为0\n",
    "    total_loss = 0.\n",
    "    # 如果数据加载器为空,返回nan\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    # 如果未指定批次数,使用数据加载器的全部批次\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # 如果指定的批次数超过数据加载器的批次数\n",
    "        # 则将批次数限制为数据加载器的实际批次数\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    # 遍历数据加载器中的批次\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        # 如果当前批次索引小于指定批次数\n",
    "        if i < num_batches:\n",
    "            # 计算当前批次的损失\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            # 累加损失值\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    # 返回平均损失\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0691332-84d0-48b3-b462-a885ddeb4fca",
   "metadata": {},
   "source": [
    "- If you have a machine with a CUDA-supported GPU, the LLM will train on the GPU without making any changes to the code\n",
    "- 如果你有支持CUDA的GPU，LLM将在GPU上训练而无需对代码做任何更改\n",
    "- Via the `device` setting, we ensure that the data is loaded onto the same device as the LLM model\n",
    "- 通过`device`设置，我们确保数据被加载到与LLM模型相同的设备上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "56f5b0c9-1065-4d67-98b9-010e42fc1e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 10.98758347829183\n",
      "Validation loss: 10.981106758117676\n"
     ]
    }
   ],
   "source": [
    "# 检查是否有可用的CUDA GPU,如果有则使用GPU,否则使用CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 注意:\n",
    "# 取消注释以下代码可以在Apple Silicon芯片上运行(如果适用)\n",
    "# 根据在M3 MacBook Air上的测试,速度约为Apple CPU的2倍\n",
    "# 但是可能会导致损失值略有不同\n",
    "\n",
    "#if torch.cuda.is_available():\n",
    "#    device = torch.device(\"cuda\")  # 如果有CUDA GPU则使用\n",
    "#elif torch.backends.mps.is_available():\n",
    "#    device = torch.device(\"mps\")   # 如果有Apple Silicon则使用MPS\n",
    "#else:\n",
    "#    device = torch.device(\"cpu\")   # 否则使用CPU\n",
    "#\n",
    "# print(f\"Using {device} device.\")  # 打印使用的设备类型\n",
    "\n",
    "\n",
    "# 将模型移动到指定设备(对于nn.Module类,不需要赋值回model变量)\n",
    "model.to(device)\n",
    "\n",
    "# 设置随机种子以确保数据加载器的shuffle操作可重现\n",
    "torch.manual_seed(123)\n",
    "\n",
    "# 禁用梯度跟踪以提高效率(因为此时还未开始训练)\n",
    "with torch.no_grad():\n",
    "    # 计算训练集损失\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "    # 计算验证集损失\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "\n",
    "# 打印训练和验证损失\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43875e95-190f-4b17-8f9a-35034ba649ec",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/mental-model-1.webp\" width=400px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9339f8d-00cb-4206-af67-58c32bd72055",
   "metadata": {
    "id": "b9339f8d-00cb-4206-af67-58c32bd72055"
   },
   "source": [
    "## 5.2 Training an LLM\n",
    "## 5.2 训练大语言模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652a4cf4-e98f-46d9-bdec-60e7ccb8d6bd",
   "metadata": {},
   "source": [
    "- In this section, we finally implement the code for training the LLM\n",
    "- 在本节中,我们终于实现了训练大语言模型的代码\n",
    "- We focus on a simple training function (if you are interested in augmenting this training function with more advanced techniques, such as learning rate warmup, cosine annealing, and gradient clipping, please refer to [Appendix D](../../appendix-D/01_main-chapter-code))\n",
    "- 我们专注于一个简单的训练函数(如果你对使用更高级的技术来增强这个训练函数感兴趣,比如学习率预热、余弦退火和梯度裁剪,请参考[附录D](../../appendix-D/01_main-chapter-code))\n",
    "\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/train-steps.webp\" width=300px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "Mtp4gY0ZO-qq",
   "metadata": {
    "id": "Mtp4gY0ZO-qq"
   },
   "outputs": [],
   "source": [
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                       eval_freq, eval_iter, start_context, tokenizer):\n",
    "    # 初始化列表用于存储训练过程中的损失值和已处理的token数量\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    # 初始化已处理的token数量和全局步数计数器\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    # 遍历训练的每个epoch\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # 将模型设置为训练模式,启用dropout等\n",
    "        \n",
    "        # 遍历数据加载器中的每个批次\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad() # 清空之前的梯度\n",
    "            # 计算当前批次的损失\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward() # 反向传播计算梯度\n",
    "            optimizer.step() # 根据梯度更新模型参数\n",
    "            # 累计已处理的token数量\n",
    "            tokens_seen += input_batch.numel()\n",
    "            # 更新全局步数\n",
    "            global_step += 1\n",
    "\n",
    "            # 每eval_freq步进行一次评估\n",
    "            if global_step % eval_freq == 0:\n",
    "                # 评估模型在训练集和验证集上的表现\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                # 记录损失值和token数量\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                # 打印当前训练状态\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "        # 每个epoch结束后生成示例文本\n",
    "        generate_and_print_sample(\n",
    "            model, tokenizer, device, start_context\n",
    "        )\n",
    "\n",
    "    # 返回训练过程中记录的数据\n",
    "    return train_losses, val_losses, track_tokens_seen\n",
    "\n",
    "\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()  # 将模型设置为评估模式,禁用dropout等\n",
    "    with torch.no_grad():  # 禁用梯度计算以节省内存\n",
    "        # 在训练集上评估指定数量批次的损失\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        # 在验证集上评估指定数量批次的损失\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()  # 将模型恢复为训练模式\n",
    "    return train_loss, val_loss\n",
    "\n",
    "\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()  # 将模型设置为评估模式\n",
    "    # 获取模型的上下文窗口大小\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    # 将起始文本转换为token ID并移至指定设备\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():  # 生成文本时禁用梯度计算\n",
    "        # 生成新的token序列\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model, idx=encoded,\n",
    "            max_new_tokens=50, context_size=context_size\n",
    "        )\n",
    "    # 将生成的token ID序列转换回文本\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    # 打印生成的文本,将换行符替换为空格以便于显示\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))\n",
    "    model.train()  # 将模型恢复为训练模式"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a301b333-b9d4-4eeb-a212-3a9874e3ac47",
   "metadata": {},
   "source": [
    "- Now, let's train the LLM using the training function defined above:\n",
    "- 现在，让我们使用上面定义的训练函数来训练LLM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3422000b-7aa2-485b-92df-99372cd22311",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3422000b-7aa2-485b-92df-99372cd22311",
    "outputId": "0e046603-908d-4093-8ae5-ef2f632639fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 9.783, Val loss 9.927\n",
      "Ep 1 (Step 000005): Train loss 7.985, Val loss 8.335\n",
      "Every effort moves you,,,,,,,,,,,,.                                     \n",
      "Ep 2 (Step 000010): Train loss 6.753, Val loss 7.048\n",
      "Ep 2 (Step 000015): Train loss 6.114, Val loss 6.573\n",
      "Every effort moves you, and,, and, and,,,,, and, and,,,,,,,,,,,,,, and,,,, and,, and,,,,, and,,,,,,\n",
      "Ep 3 (Step 000020): Train loss 5.525, Val loss 6.490\n",
      "Ep 3 (Step 000025): Train loss 5.324, Val loss 6.387\n",
      "Every effort moves you, and to the picture.                      \"I, and the of the of the's the honour, and, and I had been, and I\n",
      "Ep 4 (Step 000030): Train loss 4.761, Val loss 6.360\n",
      "Ep 4 (Step 000035): Train loss 4.461, Val loss 6.258\n",
      "Every effort moves you of the to the picture--as of the picture--as I had been \" it was his \" I was the     \"I was his I had been the his pictures--and it the picture and I had been the picture of\n",
      "Ep 5 (Step 000040): Train loss 3.833, Val loss 6.196\n",
      "Every effort moves you know the \"Oh, and he was not the fact by his last word.         \"I was.      \"Oh, I felt a little a little the    \n",
      "Ep 6 (Step 000045): Train loss 3.352, Val loss 6.139\n",
      "Ep 6 (Step 000050): Train loss 2.861, Val loss 6.112\n",
      "Every effort moves you know; and my dear, and he was not the fact with a little of the house of the fact of the fact, and.                       \n",
      "Ep 7 (Step 000055): Train loss 2.347, Val loss 6.138\n",
      "Ep 7 (Step 000060): Train loss 2.084, Val loss 6.179\n",
      "Every effort moves you know,\" was one of the picture for nothing--I told Mrs.  \"I looked--as of the fact, and I felt him--his back his head to the donkey. \"Oh, and_--because he had always _\n",
      "Ep 8 (Step 000065): Train loss 1.521, Val loss 6.176\n",
      "Ep 8 (Step 000070): Train loss 1.272, Val loss 6.178\n",
      "Every effort moves you?\" \"I didn't bear the picture--I told me.  \"I looked up, and went on groping and Mrs. I was back the head to look up at the honour being _mine_--because he was when I\n",
      "Ep 9 (Step 000075): Train loss 1.000, Val loss 6.277\n",
      "Ep 9 (Step 000080): Train loss 0.718, Val loss 6.281\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "Ep 10 (Step 000085): Train loss 0.506, Val loss 6.325\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to the donkey again. I saw that, and down the room, when I\n"
     ]
    }
   ],
   "source": [
    "# 注意:\n",
    "# 取消下面代码的注释来计算执行时间\n",
    "# import time \n",
    "# start_time = time.time()\n",
    "\n",
    "# 设置随机种子以确保结果可重现\n",
    "torch.manual_seed(123)\n",
    "# 使用124M参数配置初始化GPT模型\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "# 将模型移至指定设备(CPU/GPU)\n",
    "model.to(device)\n",
    "# 初始化AdamW优化器,设置学习率和权重衰减\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "\n",
    "# 设置训练轮数为10\n",
    "num_epochs = 10\n",
    "# 调用训练函数开始训练模型\n",
    "# 调用train_model_simple函数训练模型,返回训练损失、验证损失和已处理的token数\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model,              # 要训练的GPT模型\n",
    "    train_loader,       # 训练数据加载器\n",
    "    val_loader,         # 验证数据加载器  \n",
    "    optimizer,          # 优化器(AdamW)\n",
    "    device,             # 训练设备(CPU/GPU)\n",
    "    num_epochs=num_epochs,  # 训练轮数(10轮)\n",
    "    eval_freq=5,        # 每5个批次评估一次验证集\n",
    "    eval_iter=5,        # 每次评估使用5个批次\n",
    "    start_context=\"Every effort moves you\",  # 用于生成示例文本的起始上下文\n",
    "    tokenizer=tokenizer # 分词器,用于文本转换\n",
    ")\n",
    "\n",
    "# 注意:\n",
    "# 取消下面代码的注释来显示执行时间\n",
    "# end_time = time.time()\n",
    "# execution_time_minutes = (end_time - start_time) / 60\n",
    "# print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0WSRu2i0iHJE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "0WSRu2i0iHJE",
    "outputId": "9d36c61b-517d-4f07-a7e8-4563aff78b11"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 导入matplotlib库用于绘图\n",
    "import matplotlib.pyplot as plt\n",
    "# 导入MaxNLocator用于设置x轴刻度为整数\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    # 创建一个5x3英寸大小的图形和坐标轴对象\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # 在第一个y轴上绘制训练损失曲线\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    # 在同一个y轴上绘制验证损失曲线,使用虚线样式\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    # 设置x轴标签为\"Epochs\"\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    # 设置y轴标签为\"Loss\" \n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    # 在右上角添加图例\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    # 设置x轴刻度为整数\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "    # 创建第二个x轴,共享y轴\n",
    "    ax2 = ax1.twiny()\n",
    "    # 绘制一个透明的曲线用于对齐刻度\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)\n",
    "    # 设置第二个x轴的标签为\"Tokens seen\"\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "\n",
    "    # 自动调整布局,确保所有元素可见\n",
    "    fig.tight_layout()\n",
    "    # 将图形保存为PDF文件\n",
    "    plt.savefig(\"loss-plot.pdf\")\n",
    "    # 显示图形\n",
    "    plt.show()\n",
    "\n",
    "# 创建一个从0到num_epochs的等间距张量,长度与train_losses相同\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "# 调用绘图函数绘制损失曲线\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc83ded-5f80-4e1c-bf4d-ccb59999d995",
   "metadata": {},
   "source": [
    "- Looking at the results above, we can see that the model starts out generating incomprehensible strings of words, whereas towards the end, it's able to produce grammatically more or less correct sentences\n",
    "- 从上面的结果可以看出,模型一开始生成的是无法理解的词串,而到最后,它能够生成语法上或多或少正确的句子\n",
    "\n",
    "- However, based on the training and validation set losses, we can see that the model starts overfitting\n",
    "- 然而,根据训练集和验证集的损失,我们可以看到模型开始过拟合\n",
    "\n",
    "- If we were to check a few passages it writes towards the end, we would find that they are contained in the training set verbatim -- it simply memorizes the training data\n",
    "- 如果我们检查它在最后写的一些段落,我们会发现它们完全包含在训练集中 -- 它只是简单地记住了训练数据\n",
    "\n",
    "- Later, we will cover decoding strategies that can mitigate this memorization by a certain degree\n",
    "- 稍后,我们将介绍可以在一定程度上缓解这种记忆的解码策略\n",
    "\n",
    "- Note that the overfitting here occurs because we have a very, very small training set, and we iterate over it so many times\n",
    "- 注意,这里的过拟合发生是因为我们的训练集非常非常小,而且我们对它进行了多次迭代\n",
    "\n",
    "  - The LLM training here primarily serves educational purposes; we mainly want to see that the model can learn to produce coherent text\n",
    "  - 这里的LLM训练主要用于教育目的;我们主要想看到模型能够学会生成连贯的文本\n",
    "  \n",
    "  - Instead of spending weeks or months on training this model on vast amounts of expensive hardware, we load pretrained weights later\n",
    "  - 我们不会花费数周或数月在大量昂贵的硬件上训练这个模型,而是稍后加载预训练的权重"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb380c42-b31c-4ee1-b8b9-244094537272",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/mental-model-2.webp\" width=350px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de713235-1561-467f-bf63-bf11ade383f0",
   "metadata": {},
   "source": [
    "**If you are interested in augmenting this training function with more advanced techniques, such as learning rate warmup, cosine annealing, and gradient clipping, please refer to [Appendix D](../../appendix-D/01_main-chapter-code)**\n",
    "**如果您对使用更高级的技术来增强这个训练函数感兴趣，比如学习率预热、余弦退火和梯度裁剪，请参考[附录D](../../appendix-D/01_main-chapter-code)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5cdf2f-09a5-4eb0-a20a-d7aac5c14c2c",
   "metadata": {},
   "source": [
    "**If you are interested in a larger training dataset and longer training run, see [../03_bonus_pretraining_on_gutenberg](../03_bonus_pretraining_on_gutenberg)**\n",
    "**如果您对更大的训练数据集和更长时间的训练感兴趣，请参阅[../03_bonus_pretraining_on_gutenberg](../03_bonus_pretraining_on_gutenberg)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699f45fc-bf78-42f2-bd24-2355db41b28f",
   "metadata": {
    "id": "699f45fc-bf78-42f2-bd24-2355db41b28f"
   },
   "source": [
    "## 5.3 Decoding strategies to control randomness\n",
    "## 5.3 控制随机性的解码策略"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be9086e-2c27-41da-97d0-49137d0ba3c7",
   "metadata": {},
   "source": [
    "- Inference is relatively cheap with a relatively small LLM as the GPT model we trained above, so there's no need to use a GPU for it in case you used a GPU for training it above\n",
    "- 对于我们上面训练的GPT这样相对较小的LLM来说,推理的成本相对较低,因此即使您之前使用GPU进行训练,现在也不需要使用GPU\n",
    "\n",
    "- Using the `generate_text_simple` function (from the previous chapter) that we used earlier inside the simple training function, we can generate new text one word (or token) at a time\n",
    "- 使用我们之前在简单训练函数中使用的`generate_text_simple`函数(来自上一章),我们可以一次生成一个词(或标记)的新文本\n",
    "\n",
    "- As explained in section 5.1.2, the next generated token is the token corresponding to the largest probability score among all tokens in the vocabulary\n",
    "- 正如5.1.2节所解释的,下一个生成的标记是词汇表中所有标记中概率分数最大的标记"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2734cee0-f6f9-42d5-b71c-fa7e0ef28b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you?\"\n",
      "\n",
      "\"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 将模型移到CPU上\n",
    "model.to(\"cpu\")\n",
    "# 将模型设置为评估模式\n",
    "model.eval()\n",
    "\n",
    "# 获取GPT-2的分词器\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "# 使用generate_text_simple函数生成文本\n",
    "token_ids = generate_text_simple(\n",
    "    # 传入模型\n",
    "    model=model,\n",
    "    # 将输入文本转换为token ID序列\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    # 设置最多生成25个新token\n",
    "    max_new_tokens=25,\n",
    "    # 设置上下文长度\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "# 打印生成的文本,将token ID转换回文本\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25dbe31-bb7c-4893-b25b-47d0492d4aa4",
   "metadata": {},
   "source": [
    "- Even if we execute the `generate_text_simple` function above multiple times, the LLM will always generate the same outputs\n",
    "- 即使我们多次执行上面的`generate_text_simple`函数,LLM也会始终生成相同的输出\n",
    "- We now introduce two concepts, so-called decoding strategies, to modify the `generate_text_simple`: *temperature scaling* and *top-k* sampling  \n",
    "- 现在我们介绍两个概念,即所谓的解码策略,用来修改`generate_text_simple`:*温度缩放*和*top-k*采样\n",
    "- These will allow the model to control the randomness and diversity of the generated text\n",
    "- 这些将允许模型控制生成文本的随机性和多样性"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb6f380-a798-4fd9-825c-17b7cd29a994",
   "metadata": {},
   "source": [
    "### 5.3.1 Temperature scaling\n",
    "### 5.3.1 温度缩放"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f4f53c-0612-43d3-aa82-52447eac50fa",
   "metadata": {},
   "source": [
    " - Previously, we always sampled the token with the highest probability as the next token using `torch.argmax`\n",
    "- 之前,我们总是使用`torch.argmax`来采样概率最高的标记作为下一个标记\n",
    " - To add variety, we can sample the next token using The `torch.multinomial(probs, num_samples=1)`, sampling from a probability distribution  \n",
    "- 为了增加多样性,我们可以使用`torch.multinomial(probs, num_samples=1)`来从概率分布中采样下一个标记\n",
    " - Here, each index's chance of being picked corresponds to its probability in the input tensor\n",
    "- 在这里,每个索引被选中的概率对应于输入张量中的概率值"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7531bae-d5de-44c0-bc78-78fed077e22a",
   "metadata": {},
   "source": [
    "- Here's a little recap of generating the next token, assuming a very small vocabulary for illustration purposes:\n",
    "- 这里简单回顾一下如何生成下一个标记,为了说明目的我们假设一个很小的词汇表:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "01a5ce39-3dc8-4c35-96bc-6410a1e42412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward\n"
     ]
    }
   ],
   "source": [
    "# 定义一个简单的词汇表,将单词映射到索引\n",
    "vocab = { \n",
    "    \"closer\": 0,\n",
    "    \"every\": 1, \n",
    "    \"effort\": 2, \n",
    "    \"forward\": 3,\n",
    "    \"inches\": 4,\n",
    "    \"moves\": 5, \n",
    "    \"pizza\": 6,\n",
    "    \"toward\": 7,\n",
    "    \"you\": 8,\n",
    "} \n",
    "\n",
    "# 创建一个反向词汇表,将索引映射回单词\n",
    "inverse_vocab = {v: k for k, v in vocab.items()}\n",
    "\n",
    "# 假设输入是\"every effort moves you\",LLM\n",
    "# 返回下一个标记的logits值:\n",
    "next_token_logits = torch.tensor(\n",
    "    [4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",
    ")\n",
    "\n",
    "# 对logits应用softmax函数得到概率分布\n",
    "probas = torch.softmax(next_token_logits, dim=0)\n",
    "# 使用argmax获取概率最高的标记ID\n",
    "next_token_id = torch.argmax(probas).item()\n",
    "\n",
    "# 打印生成的下一个标记\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6400572f-b3c8-49e2-95bc-433e55c5b3a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toward\n"
     ]
    }
   ],
   "source": [
    "# 设置随机种子以确保结果可重现\n",
    "torch.manual_seed(123)\n",
    "# 使用multinomial从概率分布中采样一个token\n",
    "next_token_id = torch.multinomial(probas, num_samples=1).item()\n",
    "# 打印采样得到的token对应的单词\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63d0a27-830b-42b5-9986-6d1a7de04dd9",
   "metadata": {},
   "source": [
    "- Instead of determining the most likely token via `torch.argmax`, we use `torch.multinomial(probas, num_samples=1)` to determine the most likely token by sampling from the softmax distribution\n",
    "- 我们不使用`torch.argmax`来确定最可能的标记,而是使用`torch.multinomial(probas, num_samples=1)`从softmax分布中采样来确定最可能的标记\n",
    "- For illustration purposes, let's see what happens when we sample the next token 1,000 times using the original softmax probabilities:\n",
    "- 为了说明目的,让我们看看使用原始softmax概率采样1000次下一个标记会发生什么:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b23b863e-252a-403c-b5b1-62bc0a42319f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71 x closer\n",
      "2 x every\n",
      "0 x effort\n",
      "544 x forward\n",
      "2 x inches\n",
      "1 x moves\n",
      "0 x pizza\n",
      "376 x toward\n",
      "4 x you\n"
     ]
    }
   ],
   "source": [
    "# 定义一个函数来打印采样得到的标记\n",
    "def print_sampled_tokens(probas):\n",
    "    # 设置随机种子以确保结果可重现\n",
    "    torch.manual_seed(123) # Manual seed for reproducibility\n",
    "    # 从概率分布中采样1000次,每次采样1个标记\n",
    "    sample = [torch.multinomial(probas, num_samples=1).item() for i in range(1_000)]\n",
    "    # 统计每个标记出现的频率\n",
    "    sampled_ids = torch.bincount(torch.tensor(sample))\n",
    "    # 遍历每个标记ID及其频率\n",
    "    for i, freq in enumerate(sampled_ids):\n",
    "        # 打印标记出现的次数及对应的单词\n",
    "        print(f\"{freq} x {inverse_vocab[i]}\")\n",
    "\n",
    "# 调用函数打印采样结果\n",
    "print_sampled_tokens(probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e7d9cf-a26d-4d9a-8664-4af1efa73832",
   "metadata": {},
   "source": [
    "- We can control the distribution and selection process via a concept called temperature scaling\n",
    "- 我们可以通过一个叫做温度缩放的概念来控制分布和选择过程\n",
    "- \"Temperature scaling\" is just a fancy word for dividing the logits by a number greater than 0\n",
    "- \"温度缩放\"只是将logits除以一个大于0的数的花哨说法\n",
    "- Temperatures greater than 1 will result in more uniformly distributed token probabilities after applying the softmax\n",
    "- 温度大于1会导致在应用softmax后得到更均匀分布的标记概率\n",
    "- Temperatures smaller than 1 will result in more confident (sharper or more peaky) distributions after applying the softmax\n",
    "- 温度小于1会导致在应用softmax后得到更自信(更尖锐或更有峰值)的分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0759e4c8-5362-467c-bec6-b0a19d1ba43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一个函数,接收logits和temperature作为参数,实现带温度的softmax计算\n",
    "def softmax_with_temperature(logits, temperature):\n",
    "    # 将logits除以temperature进行缩放\n",
    "    scaled_logits = logits / temperature\n",
    "    # 对缩放后的logits应用softmax函数,dim=0表示在第0维度上进行softmax\n",
    "    return torch.softmax(scaled_logits, dim=0)\n",
    "\n",
    "# 定义不同的温度值:1表示原始分布,0.1表示更自信的分布,5表示更均匀的分布\n",
    "temperatures = [1, 0.1, 5]  # Original, higher confidence, and lower confidence\n",
    "\n",
    "# 使用列表推导式,对每个温度值计算对应的概率分布\n",
    "scaled_probas = [softmax_with_temperature(next_token_logits, T) for T in temperatures]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2e66e613-4aca-4296-a984-ddd0d80c6578",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 绘图部分\n",
    "# 创建一个包含词汇表长度的序列作为x轴坐标\n",
    "x = torch.arange(len(vocab))\n",
    "# 设置柱状图的宽度\n",
    "bar_width = 0.15\n",
    "\n",
    "# 创建一个5x3大小的图形和坐标轴对象\n",
    "fig, ax = plt.subplots(figsize=(5, 3))\n",
    "# 对每个温度值循环绘制柱状图\n",
    "for i, T in enumerate(temperatures):\n",
    "    # 绘制柱状图,x轴位置根据索引i偏移,使用scaled_probas[i]作为高度,设置标签包含温度值\n",
    "    rects = ax.bar(x + i * bar_width, scaled_probas[i], bar_width, label=f'Temperature = {T}')\n",
    "\n",
    "# 设置y轴标签为\"Probability\"\n",
    "ax.set_ylabel('Probability')\n",
    "# 设置x轴刻度位置\n",
    "ax.set_xticks(x)\n",
    "# 设置x轴刻度标签为词汇表中的单词,90度旋转以防重叠\n",
    "ax.set_xticklabels(vocab.keys(), rotation=90)\n",
    "# 添加图例\n",
    "ax.legend()\n",
    "\n",
    "# 自动调整布局以防止标签被切割\n",
    "plt.tight_layout()\n",
    "# 将图保存为PDF文件\n",
    "plt.savefig(\"temperature-plot.pdf\")\n",
    "# 显示图形\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d750e989-842a-4cfa-a44b-cf44d6e49163",
   "metadata": {},
   "source": [
    "- We can see that the rescaling via temperature 0.1 results in a sharper distribution, approaching `torch.argmax`, such that the most likely word is almost always selected:\n",
    "- 我们可以看到，通过温度0.1进行重新缩放会产生更尖锐的分布，接近`torch.argmax`，这样最可能的词几乎总是被选中："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e4600713-c51e-4f53-bf58-040a6eb362b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 x closer\n",
      "0 x every\n",
      "0 x effort\n",
      "992 x forward\n",
      "0 x inches\n",
      "0 x moves\n",
      "0 x pizza\n",
      "8 x toward\n"
     ]
    }
   ],
   "source": [
    "# 使用温度为0.1的概率分布(scaled_probas[1])打印采样的token\n",
    "print_sampled_tokens(scaled_probas[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526e93cb-8e2a-42a1-b1ba-4fd5fe64c26b",
   "metadata": {},
   "source": [
    "- The rescaled probabilities via temperature 5 are more uniformly distributed:\n",
    "- 通过温度5重新缩放的概率分布更加均匀:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9dfb48f0-bc3f-46a5-9844-33b6c9b0f4df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153 x closer\n",
      "68 x every\n",
      "55 x effort\n",
      "223 x forward\n",
      "102 x inches\n",
      "50 x moves\n",
      "43 x pizza\n",
      "218 x toward\n",
      "88 x you\n"
     ]
    }
   ],
   "source": [
    "# 使用温度为5的概率分布打印采样的token\n",
    "print_sampled_tokens(scaled_probas[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c83f0c4-3774-4375-ad7f-96440ba5fef7",
   "metadata": {},
   "source": [
    "- Assuming an LLM input \"every effort moves you\", using the approach above can sometimes result in nonsensical texts, such as \"every effort moves you pizza\", 3.2% of the time (32 out of 1000 times)\n",
    "- 假设LLM输入为\"every effort moves you\"，使用上述方法有时会产生无意义的文本，比如\"every effort moves you pizza\"，这种情况发生的概率为3.2%(1000次中有32次)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e4873e-07e4-4abb-85df-bdaedcc1a6f7",
   "metadata": {},
   "source": [
    "### 5.3.2 Top-k sampling\n",
    "### 5.3.2 Top-k 采样"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4da95a-8bb2-4f69-a9b0-a643531db5df",
   "metadata": {},
   "source": [
    "- To be able to use higher temperatures to increase output diversity and to reduce the probability of nonsensical sentences, we can restrict the sampled tokens to the top-k most likely tokens:\n",
    "- 为了能够使用更高的温度来增加输出的多样性并减少无意义句子的概率，我们可以将采样的token限制在最可能的前k个token中:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae6fffd-2730-4abe-a2d3-781fc4836f17",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/topk.webp\" width=500px>\n",
    "\n",
    "- (Please note that the numbers in this figure are truncated to two\n",
    "digits after the decimal point to reduce visual clutter. The values in the Softmax row should add up to 1.0.)\n",
    "- (请注意，为了减少视觉混乱，此图中的数字被截断为小数点后两位。Softmax行中的值加起来应该等于1.0。)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba12da5-6ff1-4008-91b8-d2d537cbc14c",
   "metadata": {},
   "source": [
    "- In code, we can implement this as follows:\n",
    "- 在代码中，我们可以按如下方式实现:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2a7f908a-e9ec-446a-b407-fb6dbf05c806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top logits: tensor([6.7500, 6.2800, 4.5100])\n",
      "Top positions: tensor([3, 7, 0])\n"
     ]
    }
   ],
   "source": [
    "# 设置top-k的值为3\n",
    "top_k = 3\n",
    "\n",
    "# 使用torch.topk获取next_token_logits中最大的k个值及其位置\n",
    "# top_logits存储k个最大值,top_pos存储这些值的位置索引\n",
    "top_logits, top_pos = torch.topk(next_token_logits, top_k)\n",
    "\n",
    "# 打印最大的k个logits值\n",
    "print(\"Top logits:\", top_logits)\n",
    "# 打印这些logits值对应的位置索引\n",
    "print(\"Top positions:\", top_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "753865ed-79c5-48b1-b9f2-ccb132ff1d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.5100,   -inf,   -inf, 6.7500,   -inf,   -inf,   -inf, 6.2800,   -inf])\n"
     ]
    }
   ],
   "source": [
    "# 使用torch.where创建新的logits张量\n",
    "# 条件: 如果next_token_logits中的值小于top_k个最大值中的最小值\n",
    "# 则将该位置的值设为负无穷\n",
    "# 否则保持原值不变\n",
    "new_logits = torch.where(\n",
    "    condition=next_token_logits < top_logits[-1],  # 判断条件:是否小于top-k中的最小值\n",
    "    input=torch.tensor(float(\"-inf\")),             # 如果条件为真,设为负无穷\n",
    "    other=next_token_logits                        # 如果条件为假,保持原值\n",
    ")\n",
    "\n",
    "# 打印处理后的logits张量\n",
    "print(new_logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa6fa49-6e99-459d-a517-d7d0f51c4f00",
   "metadata": {},
   "source": [
    "> NOTE:  \n",
    "> 注意：\n",
    ">\n",
    ">  An alternative, slightly more efficient implementation of the previous code cell is the following:\n",
    ">  以下是前一个代码单元的另一种稍微更高效的实现方式：\n",
    ">\n",
    "> ```python\n",
    "> new_logits = torch.full_like( # create tensor containing -inf values\n",
    ">    next_token_logits, -torch.inf\n",
    ">)   \n",
    "> new_logits[top_pos] = next_token_logits[top_pos] # copy top k values into the -inf tensor\n",
    "> ```\n",
    "> <br>\n",
    "> For more details, see https://github.com/rasbt/LLMs-from-scratch/discussions/326\n",
    "> 更多详情请参见 https://github.com/rasbt/LLMs-from-scratch/discussions/326\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4844f000-c329-4e7e-aa89-16a2c4ebee43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0615, 0.0000, 0.0000, 0.5775, 0.0000, 0.0000, 0.0000, 0.3610, 0.0000])\n"
     ]
    }
   ],
   "source": [
    "# 对经过top-k过滤后的logits张量应用softmax函数,得到概率分布\n",
    "topk_probas = torch.softmax(new_logits, dim=0)\n",
    "# 打印top-k采样后的概率分布\n",
    "print(topk_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56056503-a15d-4315-a3ff-46647a4c7c45",
   "metadata": {},
   "source": [
    "### 5.3.3 Modifying the text generation function\n",
    "### 5.3.3 修改文本生成函数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34770423-473d-46f6-a5fa-6b2979564d26",
   "metadata": {},
   "source": [
    "- The previous two subsections introduced temperature sampling and top-k sampling\n",
    "- 前面两个小节介绍了温度采样和top-k采样\n",
    "- Let's use these two concepts to modify the `generate_simple` function we used to generate text via the LLM earlier, creating a new `generate` function:\n",
    "- 让我们使用这两个概念来修改之前用于通过LLM生成文本的`generate_simple`函数，创建一个新的`generate`函数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8e318891-bcc0-4d71-b147-33ce55febfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
    "    \"\"\"\n",
    "    文本生成函数\n",
    "    参数:\n",
    "        model: GPT模型\n",
    "        idx: 输入token序列\n",
    "        max_new_tokens: 最大生成token数量\n",
    "        context_size: 上下文窗口大小\n",
    "        temperature: 温度参数,控制采样随机性\n",
    "        top_k: top-k采样的k值\n",
    "        eos_id: 结束符token的id\n",
    "    \"\"\"\n",
    "    # 循环生成指定数量的新token\n",
    "    for _ in range(max_new_tokens):\n",
    "        # 截取最后context_size个token作为条件输入\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        \n",
    "        # 使用no_grad上下文管理器,不计算梯度\n",
    "        with torch.no_grad():\n",
    "            # 通过模型获取logits输出\n",
    "            logits = model(idx_cond)\n",
    "        \n",
    "        # 只保留最后一个时间步的logits\n",
    "        logits = logits[:, -1, :]\n",
    "\n",
    "        # 如果指定了top_k,进行top-k采样过滤\n",
    "        if top_k is not None:\n",
    "            # 获取logits中最大的top_k个值\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            # 获取第k大的值作为阈值\n",
    "            min_val = top_logits[:, -1]\n",
    "            # 将小于阈值的logits设置为负无穷\n",
    "            logits = torch.where(logits < min_val, torch.tensor(float(\"-inf\")).to(logits.device), logits)\n",
    "\n",
    "        # 如果temperature大于0,进行温度采样\n",
    "        if temperature > 0.0:\n",
    "            # 对logits进行温度缩放\n",
    "            logits = logits / temperature\n",
    "\n",
    "            # 使用softmax将logits转换为概率分布\n",
    "            probs = torch.softmax(logits, dim=-1)  # (batch_size, context_len)\n",
    "\n",
    "            # 从概率分布中采样下一个token\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)  # (batch_size, 1)\n",
    "\n",
    "        # 如果temperature为0,直接选择概率最大的token\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch_size, 1)\n",
    "\n",
    "        # 如果生成了结束符token且指定了eos_id,提前结束生成\n",
    "        if idx_next == eos_id:\n",
    "            break\n",
    "\n",
    "        # 将新生成的token拼接到序列末尾\n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # (batch_size, num_tokens+1)\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "aa2a0d7d-0457-42d1-ab9d-bd67683e7ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you know began to my surprise, a little it was the\n",
      "\"Ah enough\n"
     ]
    }
   ],
   "source": [
    "# 设置随机种子为123,保证结果可复现\n",
    "torch.manual_seed(123)\n",
    "\n",
    "# 使用generate函数生成文本\n",
    "token_ids = generate(\n",
    "    # 传入训练好的模型\n",
    "    model=model,\n",
    "    # 将输入文本转换为token id序列作为初始条件\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    # 最多生成15个新token\n",
    "    max_new_tokens=15,\n",
    "    # 设置上下文窗口大小为模型配置中的context_length\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "    # 使用top-k采样,只保留概率最大的前25个token\n",
    "    top_k=25,\n",
    "    # 设置采样温度为1.4,增加采样的随机性\n",
    "    temperature=1.4\n",
    ")\n",
    "\n",
    "# 将生成的token id序列转换回文本并打印输出\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2002ca-f4c1-48af-9e0a-88bfc163ba0b",
   "metadata": {},
   "source": [
    "## 5.4 Loading and saving model weights in PyTorch\n",
    "## 5.4 在PyTorch中加载和保存模型权重"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc52676-f026-4566-a226-2a90269f9d53",
   "metadata": {},
   "source": [
    "- Training LLMs is computationally expensive, so it's crucial to be able to save and load LLM weights\n",
    "- 训练大语言模型需要大量计算资源，因此能够保存和加载模型权重至关重要\n",
    "\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/mental-model-3.webp\" width=400px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e4c7f9-592f-43d6-a00e-598fa01dfb82",
   "metadata": {},
   "source": [
    "- The recommended way in PyTorch is to save the model weights, the so-called `state_dict` via by applying the `torch.save` function to the `.state_dict()` method:\n",
    "- 在PyTorch中推荐的方法是通过对`.state_dict()`方法应用`torch.save`函数来保存模型权重，即所谓的`state_dict`："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3d67d869-ac04-4382-bcfb-c96d1ca80d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用torch.save()函数保存模型的状态字典(state_dict)\n",
    "# model.state_dict()包含了模型的所有参数(权重和偏置)\n",
    "# 将其保存到名为\"model.pth\"的文件中\n",
    "torch.save(model.state_dict(), \"model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e889e0-07bf-43e5-8f92-5c5c7aeaad9e",
   "metadata": {},
   "source": [
    "- Then we can load the model weights into a new `GPTModel` model instance as follows:\n",
    "- 然后我们可以按照如下方式将模型权重加载到新的`GPTModel`模型实例中："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9d57d914-60a3-47f1-b499-5352f4c457cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个新的GPT模型实例,使用124M参数配置\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "# 检查是否有可用的GPU,如果有则使用GPU,否则使用CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# 从保存的文件中加载模型权重,并将其映射到指定设备上,只加载权重数据\n",
    "model.load_state_dict(torch.load(\"model.pth\", map_location=device, weights_only=True))\n",
    "# 将模型设置为评估模式\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa81aec-9c72-4f46-8ae2-4a4fde3edbc1",
   "metadata": {},
   "source": [
    "- It's common to train LLMs with adaptive optimizers like Adam or AdamW instead of regular SGD\n",
    "- 通常使用Adam或AdamW这样的自适应优化器来训练大语言模型,而不是普通的SGD\n",
    "- These adaptive optimizers store additional parameters for each model weight, so it makes sense to save them as well in case we plan to continue the pretraining later:\n",
    "- 这些自适应优化器为每个模型权重存储额外的参数,因此如果我们计划稍后继续预训练,保存这些参数也是有意义的:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bbd175bb-edf4-450e-a6de-d3e8913c6532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用torch.save()保存模型和优化器的状态字典\n",
    "# 创建一个字典来存储两个状态字典:\n",
    "# - model_state_dict: 包含模型的权重和偏置参数\n",
    "# - optimizer_state_dict: 包含优化器的状态参数\n",
    "torch.save({\n",
    "    \"model_state_dict\": model.state_dict(),\n",
    "    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "    }, \n",
    "    \"model_and_optimizer.pth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8a0c7295-c822-43bf-9286-c45abc542868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从保存的文件中加载模型和优化器的状态字典\n",
    "checkpoint = torch.load(\"model_and_optimizer.pth\", weights_only=True)\n",
    "\n",
    "# 创建一个新的GPT模型实例\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "# 加载模型的状态字典(权重和偏置参数)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "\n",
    "# 创建一个新的AdamW优化器实例,设置学习率和权重衰减\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0005, weight_decay=0.1)\n",
    "# 加载优化器的状态字典(优化器参数)\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "# 将模型设置为训练模式\n",
    "model.train();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4194350e-0409-4a63-8ffd-d3a896509032",
   "metadata": {},
   "source": [
    "## 5.5 Loading pretrained weights from OpenAI\n",
    "## 5.5 从OpenAI加载预训练权重"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83eb6c38-7278-40e0-bd9f-8a2b1feac3ec",
   "metadata": {},
   "source": [
    "- Previously, we only trained a small GPT-2 model using a very small short-story book for educational purposes\n",
    "- 之前,我们仅使用一本很小的短篇故事书训练了一个小型GPT-2模型用于教学目的\n",
    "\n",
    "- Interested readers can also find a longer pretraining run on the complete Project Gutenberg book corpus in [../03_bonus_pretraining_on_gutenberg](../03_bonus_pretraining_on_gutenberg)\n",
    "- 感兴趣的读者可以在[../03_bonus_pretraining_on_gutenberg](../03_bonus_pretraining_on_gutenberg)中找到在完整的古腾堡计划图书语料库上进行的更长时间的预训练运行\n",
    "\n",
    "- Fortunately, we don't have to spend tens to hundreds of thousands of dollars to pretrain the model on a large pretraining corpus but can load the pretrained weights provided by OpenAI\n",
    "- 幸运的是,我们不必花费数十万到数十万美元在大型预训练语料库上预训练模型,而是可以加载OpenAI提供的预训练权重"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127ddbdb-3878-4669-9a39-d231fbdfb834",
   "metadata": {},
   "source": [
    "- For an alternative way to load the weights from the Hugging Face Hub, see [../02_alternative_weight_loading](../02_alternative_weight_loading)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75cab892-a165-4f43-9601-f517bc212ab6",
   "metadata": {},
   "source": [
    "- First, some boilerplate code to download the files from OpenAI and load the weights into Python\n",
    "- Since OpenAI used [TensorFlow](https://www.tensorflow.org/), we will have to install and use TensorFlow for loading the weights; [tqdm](https://github.com/tqdm/tqdm) is a progress bar library\n",
    "- Uncomment and run the next cell to install the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fb9fdf02-972a-444e-bf65-8ffcaaf30ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install tensorflow tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a0747edc-559c-44ef-a93f-079d60227e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.18.0\n",
      "tqdm version: 4.66.5\n"
     ]
    }
   ],
   "source": [
    "# 打印TensorFlow和tqdm的版本信息\n",
    "print(\"TensorFlow version:\", version(\"tensorflow\"))  # 打印TensorFlow版本\n",
    "print(\"tqdm version:\", version(\"tqdm\"))  # 打印tqdm版本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c5bc89eb-4d39-4287-9b0c-e459ebe7f5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从当前文件夹中的gpt_download.py相对导入\n",
    "from gpt_download import download_and_load_gpt2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff76a736-6f9f-4328-872e-f89a7b70a2cc",
   "metadata": {},
   "source": [
    "- We can then download the model weights for the 124 million parameter model as follows:\n",
    "- 然后我们可以按如下方式下载124百万参数模型的权重:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "76271dd7-108d-4f5b-9c01-6ae0aac4b395",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "checkpoint: 100%|██████████| 77.0/77.0 [00:00<00:00, 78.0kiB/s]\n",
      "encoder.json: 100%|██████████| 1.04M/1.04M [00:01<00:00, 607kiB/s] \n",
      "hparams.json: 100%|██████████| 90.0/90.0 [00:00<00:00, 43.7kiB/s]\n",
      "model.ckpt.data-00000-of-00001: 100%|██████████| 498M/498M [19:36<00:00, 423kiB/s]    \n",
      "model.ckpt.index: 100%|██████████| 5.21k/5.21k [00:00<00:00, 5.21MiB/s]\n",
      "model.ckpt.meta: 100%|██████████| 471k/471k [00:02<00:00, 173kiB/s]  \n",
      "vocab.bpe: 100%|██████████| 456k/456k [00:02<00:00, 160kiB/s]  \n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xd1 in position 9: invalid continuation byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 下载并加载124M参数的GPT-2模型权重\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# settings包含模型配置信息,params包含模型参数\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m settings, params \u001b[38;5;241m=\u001b[39m \u001b[43mdownload_and_load_gpt2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m124M\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodels_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\AI科研\\代码学习\\LLMs-from-scratch\\ch05\\01_main-chapter-code\\gpt_download.py:43\u001b[0m, in \u001b[0;36mdownload_and_load_gpt2\u001b[1;34m(model_size, models_dir)\u001b[0m\n\u001b[0;32m     41\u001b[0m tf_ckpt_path \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mtrain\u001b[38;5;241m.\u001b[39mlatest_checkpoint(model_dir)\n\u001b[0;32m     42\u001b[0m settings \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28mopen\u001b[39m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(model_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhparams.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)))\n\u001b[1;32m---> 43\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[43mload_gpt2_params_from_tf_ckpt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf_ckpt_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msettings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m settings, params\n",
      "File \u001b[1;32md:\\AI科研\\代码学习\\LLMs-from-scratch\\ch05\\01_main-chapter-code\\gpt_download.py:122\u001b[0m, in \u001b[0;36mload_gpt2_params_from_tf_ckpt\u001b[1;34m(ckpt_path, settings)\u001b[0m\n\u001b[0;32m    119\u001b[0m params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblocks\u001b[39m\u001b[38;5;124m\"\u001b[39m: [{} \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(settings[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_layer\u001b[39m\u001b[38;5;124m\"\u001b[39m])]}\n\u001b[0;32m    121\u001b[0m \u001b[38;5;66;03m# 遍历检查点中的每个变量\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, _ \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlist_variables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    123\u001b[0m     \u001b[38;5;66;03m# 加载变量并移除单一维度\u001b[39;00m\n\u001b[0;32m    124\u001b[0m     variable_array \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqueeze(tf\u001b[38;5;241m.\u001b[39mtrain\u001b[38;5;241m.\u001b[39mload_variable(ckpt_path, name))\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;66;03m# 处理变量名以提取相关部分\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anaconda\\Anaconda\\envs\\LLMs\\lib\\site-packages\\tensorflow\\python\\training\\checkpoint_utils.py:141\u001b[0m, in \u001b[0;36mlist_variables\u001b[1;34m(ckpt_dir_or_file)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain.list_variables\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlist_variables\u001b[39m(ckpt_dir_or_file):\n\u001b[0;32m    119\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Lists the checkpoint keys and shapes of variables in a checkpoint.\u001b[39;00m\n\u001b[0;32m    120\u001b[0m \n\u001b[0;32m    121\u001b[0m \u001b[38;5;124;03m  Checkpoint keys are paths in a checkpoint graph.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;124;03m    List of tuples `(key, shape)`.\u001b[39;00m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 141\u001b[0m   reader \u001b[38;5;241m=\u001b[39m \u001b[43mload_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mckpt_dir_or_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    142\u001b[0m   variable_map \u001b[38;5;241m=\u001b[39m reader\u001b[38;5;241m.\u001b[39mget_variable_to_shape_map()\n\u001b[0;32m    143\u001b[0m   names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(variable_map\u001b[38;5;241m.\u001b[39mkeys())\n",
      "File \u001b[1;32md:\\Anaconda\\Anaconda\\envs\\LLMs\\lib\\site-packages\\tensorflow\\python\\training\\checkpoint_utils.py:76\u001b[0m, in \u001b[0;36mload_checkpoint\u001b[1;34m(ckpt_dir_or_file)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain.load_checkpoint\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_checkpoint\u001b[39m(ckpt_dir_or_file):\n\u001b[0;32m     48\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Returns `CheckpointReader` for checkpoint found in `ckpt_dir_or_file`.\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \n\u001b[0;32m     50\u001b[0m \u001b[38;5;124;03m  If `ckpt_dir_or_file` resolves to a directory with multiple checkpoints,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;124;03m      checkpoints.\u001b[39;00m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m---> 76\u001b[0m   filename \u001b[38;5;241m=\u001b[39m \u001b[43m_get_checkpoint_filename\u001b[49m\u001b[43m(\u001b[49m\u001b[43mckpt_dir_or_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m filename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcheckpoint\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m file or checkpoints in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     79\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgiven directory \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m ckpt_dir_or_file)\n",
      "File \u001b[1;32md:\\Anaconda\\Anaconda\\envs\\LLMs\\lib\\site-packages\\tensorflow\\python\\training\\checkpoint_utils.py:479\u001b[0m, in \u001b[0;36m_get_checkpoint_filename\u001b[1;34m(ckpt_dir_or_file)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ckpt_dir_or_file, os\u001b[38;5;241m.\u001b[39mPathLike):\n\u001b[0;32m    478\u001b[0m   ckpt_dir_or_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mfspath(ckpt_dir_or_file)\n\u001b[1;32m--> 479\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mgfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIsDirectory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mckpt_dir_or_file\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    480\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m checkpoint_management\u001b[38;5;241m.\u001b[39mlatest_checkpoint(ckpt_dir_or_file)\n\u001b[0;32m    481\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ckpt_dir_or_file\n",
      "File \u001b[1;32md:\\Anaconda\\Anaconda\\envs\\LLMs\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py:689\u001b[0m, in \u001b[0;36mis_directory\u001b[1;34m(dirname)\u001b[0m\n\u001b[0;32m    679\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(v1\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgfile.IsDirectory\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    680\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_directory\u001b[39m(dirname):\n\u001b[0;32m    681\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Returns whether the path is a directory or not.\u001b[39;00m\n\u001b[0;32m    682\u001b[0m \n\u001b[0;32m    683\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[38;5;124;03m    True, if the path is a directory; False otherwise\u001b[39;00m\n\u001b[0;32m    688\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 689\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mis_directory_v2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Anaconda\\Anaconda\\envs\\LLMs\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py:703\u001b[0m, in \u001b[0;36mis_directory_v2\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    694\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns whether the path is a directory or not.\u001b[39;00m\n\u001b[0;32m    695\u001b[0m \n\u001b[0;32m    696\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    700\u001b[0m \u001b[38;5;124;03m  True, if the path is a directory; False otherwise\u001b[39;00m\n\u001b[0;32m    701\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 703\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_pywrap_file_io\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIsDirectory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath_to_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    704\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mOpError:\n\u001b[0;32m    705\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xd1 in position 9: invalid continuation byte"
     ]
    }
   ],
   "source": [
    "# 下载并加载124M参数的GPT-2模型权重\n",
    "# settings包含模型配置信息,params包含模型参数\n",
    "settings, params = download_and_load_gpt2(model_size=\"124M\", models_dir=\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b1a31951-d971-4a6e-9c43-11ee1168ec6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settings: {'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}\n"
     ]
    }
   ],
   "source": [
    "# 打印模型配置信息\n",
    "print(\"Settings:\", settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "857c8331-130e-46ba-921d-fa35d7a73cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter dictionary keys: dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n"
     ]
    }
   ],
   "source": [
    "# 打印参数字典的键\n",
    "print(\"Parameter dictionary keys:\", params.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c48dac94-8562-4a66-84ef-46c613cdc4cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.11010301 -0.03926672  0.03310751 ... -0.1363697   0.01506208\n",
      "   0.04531523]\n",
      " [ 0.04034033 -0.04861503  0.04624869 ...  0.08605453  0.00253983\n",
      "   0.04318958]\n",
      " [-0.12746179  0.04793796  0.18410145 ...  0.08991534 -0.12972379\n",
      "  -0.08785918]\n",
      " ...\n",
      " [-0.04453601 -0.05483596  0.01225674 ...  0.10435229  0.09783269\n",
      "  -0.06952604]\n",
      " [ 0.1860082   0.01665728  0.04611587 ... -0.09625227  0.07847701\n",
      "  -0.02245961]\n",
      " [ 0.05135201 -0.02768905  0.0499369  ...  0.00704835  0.15519823\n",
      "   0.12067825]]\n",
      "Token embedding weight tensor dimensions: (50257, 768)\n"
     ]
    }
   ],
   "source": [
    "# 打印词元嵌入权重矩阵\n",
    "print(params[\"wte\"])\n",
    "# 打印词元嵌入权重张量的维度\n",
    "print(\"Token embedding weight tensor dimensions:\", params[\"wte\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466e100c-294e-4afc-a70a-2f398ac4c104",
   "metadata": {},
   "source": [
    "- Alternatively, \"355M\", \"774M\", and \"1558M\" are also supported `model_size` arguments\n",
    "- 另外,\"355M\"、\"774M\"和\"1558M\"也是支持的`model_size`参数\n",
    "- The difference between these differently sized models is summarized in the figure below:\n",
    "- 这些不同大小模型之间的差异总结在下图中:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f19d32-5aae-4176-9f86-f391672c8f0d",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/gpt-sizes.webp?timestamp=123\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6e5076-f08d-41fc-bd8b-1cfe53538f41",
   "metadata": {},
   "source": [
    "- Above, we loaded the 124M GPT-2 model weights into Python, however we still need to transfer them into our `GPTModel` instance\n",
    "- 上面我们将124M GPT-2模型权重加载到Python中,但我们仍需要将它们传输到我们的`GPTModel`实例中\n",
    "\n",
    "- First, we initialize a new GPTModel instance  \n",
    "- 首先,我们初始化一个新的GPTModel实例\n",
    "\n",
    "- Note that the original GPT model initialized the linear layers for the query, key, and value matrices in the multi-head attention module with bias vectors, which is not required or recommended; however, to be able to load the weights correctly, we have to enable these too by setting `qkv_bias` to `True` in our implementation, too\n",
    "- 注意,原始GPT模型在多头注意力模块中使用偏置向量初始化查询、键和值矩阵的线性层,这不是必需的也不推荐;但是,为了能够正确加载权重,我们也必须通过在实现中将`qkv_bias`设置为`True`来启用这些\n",
    "\n",
    "- We are also using the `1024` token context length that was used by the original GPT-2 model(s)\n",
    "- 我们还使用了原始GPT-2模型使用的`1024`词元上下文长度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9fef90dd-0654-4667-844f-08e28339ef7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model configurations in a dictionary for compactness\n",
    "# 定义不同GPT-2模型配置的字典,包含嵌入维度、层数和注意力头数\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},  # 小型124M参数模型\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},  # 中型355M参数模型 \n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},  # 大型774M参数模型\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},  # 超大型1558M参数模型\n",
    "}\n",
    "\n",
    "# 复制基础配置并使用特定模型设置更新\n",
    "model_name = \"gpt2-small (124M)\"  # 选择使用124M小型模型\n",
    "NEW_CONFIG = GPT_CONFIG_124M.copy()  # 复制基础配置\n",
    "NEW_CONFIG.update(model_configs[model_name])  # 更新模型特定参数\n",
    "NEW_CONFIG.update({\"context_length\": 1024, \"qkv_bias\": True})  # 设置上下文长度和QKV偏置\n",
    "\n",
    "# 初始化GPT模型并设置为评估模式\n",
    "gpt = GPTModel(NEW_CONFIG)\n",
    "gpt.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272f29ac-8342-4b3d-a57d-9b0166ced314",
   "metadata": {},
   "source": [
    "- The next task is to assign the OpenAI weights to the corresponding weight tensors in our `GPTModel` instance\n",
    "- 下一个任务是将OpenAI的权重分配给我们的`GPTModel`实例中对应的权重张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f9a92229-c002-49a6-8cfb-248297ad8296",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign(left, right):\n",
    "    # 检查左右张量形状是否匹配\n",
    "    if left.shape != right.shape:\n",
    "        # 如果形状不匹配,抛出ValueError异常\n",
    "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
    "    # 将右侧张量转换为PyTorch参数并返回\n",
    "    return torch.nn.Parameter(torch.tensor(right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f22d5d95-ca5a-425c-a9ec-fc432a12d4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_weights_into_gpt(gpt, params):\n",
    "    # 加载位置嵌入权重\n",
    "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
    "    # 加载词元嵌入权重\n",
    "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
    "    \n",
    "    # 遍历每个Transformer块\n",
    "    for b in range(len(params[\"blocks\"])):\n",
    "        # 将注意力权重矩阵分割为查询、键、值三部分\n",
    "        q_w, k_w, v_w = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
    "        # 加载查询权重矩阵(需要转置)\n",
    "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
    "        # 加载键权重矩阵(需要转置)\n",
    "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
    "        # 加载值权重矩阵(需要转置)\n",
    "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
    "\n",
    "        # 将注意力偏置向量分割为查询、键、值三部分\n",
    "        q_b, k_b, v_b = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
    "        # 加载查询偏置向量\n",
    "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
    "        # 加载键偏置向量\n",
    "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
    "        # 加载值偏置向量\n",
    "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
    "\n",
    "        # 加载注意力输出投影层的权重(需要转置)\n",
    "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.weight, \n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
    "        # 加载注意力输出投影层的偏置\n",
    "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.bias, \n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        # 加载前馈网络第一层的权重(需要转置)\n",
    "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].weight, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
    "        # 加载前馈网络第一层的偏置\n",
    "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].bias, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
    "        # 加载前馈网络第三层(输出层)的权重(需要转置)\n",
    "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].weight, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
    "        # 加载前馈网络第三层(输出层)的偏置\n",
    "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].bias, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        # 加载第一个层归一化的缩放参数\n",
    "        gpt.trf_blocks[b].norm1.scale = assign(\n",
    "            gpt.trf_blocks[b].norm1.scale, \n",
    "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
    "        # 加载第一个层归一化的偏移参数\n",
    "        gpt.trf_blocks[b].norm1.shift = assign(\n",
    "            gpt.trf_blocks[b].norm1.shift, \n",
    "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
    "        # 加载第二个层归一化的缩放参数\n",
    "        gpt.trf_blocks[b].norm2.scale = assign(\n",
    "            gpt.trf_blocks[b].norm2.scale, \n",
    "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
    "        # 加载第二个层归一化的偏移参数\n",
    "        gpt.trf_blocks[b].norm2.shift = assign(\n",
    "            gpt.trf_blocks[b].norm2.shift, \n",
    "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
    "\n",
    "    # 加载最终层归一化的缩放参数\n",
    "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
    "    # 加载最终层归一化的偏移参数\n",
    "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
    "    # 加载输出头的权重(与词元嵌入共享权重)\n",
    "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])\n",
    "    \n",
    "# 加载权重并将模型移至指定设备    \n",
    "load_weights_into_gpt(gpt, params)\n",
    "gpt.to(device);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7472cb-54dc-4311-96d8-b2694f885cee",
   "metadata": {},
   "source": [
    "- If the model is loaded correctly, we can use it to generate new text using our previous `generate` function:\n",
    "- 如果模型加载正确,我们可以使用之前的`generate`函数来生成新的文本:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1f690253-f845-4347-b7b6-43fabbd2affa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you toward finding an ideal new way to practice something!\n",
      "\n",
      "What makes us want to be on top of that?\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 设置随机种子以确保结果可重现\n",
    "torch.manual_seed(123)\n",
    "\n",
    "# 使用GPT模型生成文本\n",
    "token_ids = generate(\n",
    "    # 传入GPT模型实例\n",
    "    model=gpt,\n",
    "    # 将输入提示文本转换为token ID并移至指定设备\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(device),\n",
    "    # 设置要生成的新token数量为25个\n",
    "    max_new_tokens=25,\n",
    "    # 设置上下文窗口大小,使用配置文件中定义的长度\n",
    "    context_size=NEW_CONFIG[\"context_length\"],\n",
    "    # 设置top_k采样参数为50,即只从概率最高的50个token中采样\n",
    "    top_k=50,\n",
    "    # 设置temperature(温度)参数为1.5,较高的温度会增加采样的随机性\n",
    "    temperature=1.5\n",
    ")\n",
    "\n",
    "# 将生成的token ID序列转换回可读文本并打印输出\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d079f98-a7c4-462e-8416-5a64f670861c",
   "metadata": {},
   "source": [
    "- We know that we loaded the model weights correctly because the model can generate coherent text; if we made even a small mistake, the model would not be able to do that\n",
    "- 我们知道模型权重加载正确,因为模型能够生成连贯的文本;如果我们犯了哪怕一个小错误,模型都无法做到这一点"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28493b9b-a1ae-4f31-87bc-c10ee4447f44",
   "metadata": {},
   "source": [
    "- For an alternative way to load the weights from the Hugging Face Hub, see [../02_alternative_weight_loading](../02_alternative_weight_loading)\n",
    "- 关于从Hugging Face Hub加载权重的另一种方式,请参见[../02_alternative_weight_loading](../02_alternative_weight_loading)\n",
    "- If you are interested in seeing how the GPT architecture compares to the Llama architecture (a popular LLM developed by Meta AI), see the bonus content at [../07_gpt_to_llama](../07_gpt_to_llama)\n",
    "- 如果你想了解GPT架构与Llama架构(Meta AI开发的一个流行的大语言模型)的比较,请查看[../07_gpt_to_llama](../07_gpt_to_llama)的额外内容"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a66474-230d-4180-a8ff-843e04f1f1c4",
   "metadata": {},
   "source": [
    "## Summary and takeaways\n",
    "## 总结和要点"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7ed189-a633-458c-bf12-4f70b42684b8",
   "metadata": {},
   "source": [
    "- See the [./gpt_train.py](./gpt_train.py) script, a self-contained script for training\n",
    "- The [./gpt_generate.py](./gpt_generate.py) script loads pretrained weights from OpenAI and generates text based on a prompt\n",
    "- You can find the exercise solutions in [./exercise-solutions.ipynb](./exercise-solutions.ipynb)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
